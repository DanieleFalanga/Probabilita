\documentclass[12pt]{article}
\usepackage[top=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{parskip}
\usepackage{graphicx}


\newtheorem{definition}{Definizione}[section]
\newtheorem{proposition}{Proposizione}[section]
\newtheorem{theorem}{Teorema}[section]
\newtheorem{nota}{Nota}[section]
\newtheorem{notaAMargine}{Nota a margine}[section]

\title{\textbf{Foglio 7}}
\author{Daniele Falanga}
\date{}

\begin{document}
\maketitle

\subsection*{Esercizio 1}

\subsection*{Esercizio 2}
Assumendo che su una popolazione di cento persone, in media \(\lambda = 2\), sono mancini, per calcolare la probabilità che almeno 3 siano mancini:

\begin{align*}
    &P(X \ge 3) = 1 - (P(X = 0) + P(X = 1) + P(X = 2)) = \\    
    &P(X \ge 3) = 1 - (\frac{2^0}{1}e^{-2} + \frac{2}{1}e^{-2} + \frac{2^2}{2}e^{-2}) = \\
    &P(X \ge 3) = 1-5e^{-2} = 0.32 = 32\%
\end{align*}  

\newpage
\subsection*{Esercizio 3}
Date le seguenti variabili aleatorie:
\begin{itemize}
    \item Y = y numero di mail spam 
    \item Z = z numero di mail non spam
    \item X = y+z numero di mail totale in arrivo  
\end{itemize}

La funzione di massa di probabilità congiunta:
\begin{align*}
    &P(Y=y, Z=z) = P(Y=y, X = y+z) \\
    &P(Y=y, X = y+z) = P(Y=y|X = y+z)\cdot P(X) \\    
\end{align*}

Modello le due probabilità in questo modo:
\begin{itemize}
    \item \(P(Y,y|X = y+z) = \binom{y+z}{y}\cdot p^y \cdot (1-p)^{y-z} \) : numero di modi possibili di scegliere y mail dalle y+z in arrivo per le rispettive probabilità
    \item \(P(X = y+z) = \frac{\lambda^{y+z}}{(y+z)!} e^{-\lambda}\)
\end{itemize}

Sostituendo:
\begin{align*}
    &P(Y=y, X = y+z) = P(Y=y|X = y+z)\cdot P(X) = \\
    &\binom{y+z}{y}\cdot p^y \cdot (1-p)^{y-z} \cdot \frac{\lambda^{y+z}}{(y+z)!} e^{-\lambda} = \\
    &\frac{(y+z)!}{y!z!}p^y(1-p)^z \cdot \frac{\lambda^y \lambda^z}{(y+z)!} e^{\lambda p (1-p)} = \\
    &\frac{(\lambda p)^y}{y!}e^{-\lambda p} \cdot \frac{(\lambda (1-p))^z}{z!}e^{-\lambda (1-p)} \\        
\end{align*}

Le distribuzioni marginali:
\begin{align*}
    &P(N_1 = y) = \sum_{z=0}^{\infty} P(P(Y=y, X = y+z)) = \\
    &\frac{(\lambda p)^y}{y!}e^{-\lambda p} \sum_{z=0}^{\infty}\frac{(\lambda (1-p))^z}{z!}e^{-\lambda (1-p)} = \\
    &\frac{(\lambda p)^y}{y!}e^{-\lambda p} \quad \text{La sommatoria è funzione di massa di una Poisson, quindi uguale ad 1}
\end{align*}
Analogamente:
\begin{align*}
    &P(N_2 = z) = \sum_{y=0}^{\infty} P(P(Y=y, X = y+z)) = \\
    &\frac{(\lambda (1-p))^z}{z!}e^{-\lambda (1-p)} \sum_{y=0}^{\infty} = \frac{(\lambda p)^y}{y!}e^{-\lambda p}\\
    &\frac{(\lambda (1-p))^z}{z!}e^{-\lambda (1-p)} 
\end{align*}

Esendo le marginali, il prodotto delle congiunte, le variabili sono indipendenti
\subsection*{Esercizio 4}

Scrivendo le variabili in questo modo:
\begin{itemize}
    \item X = numero medio lanci effettuati 
    \item Y = numero di teste ottenute
    \item Z = numero di croci ottenute 
\end{itemize}

Modellando come l'esercizio 3 si risolve in modo analogo

\newpage
\subsection*{Esercizio 5}
Modellando come segue:
\begin{align*}
    &X = \text{numero consecutivo di risultati al k-esimo lancio}\\
    &p = \text{numero di teste consecutive} \\
    &1-p = \text{numero di croci consecutive} \\   
\end{align*}
Essendo eventi disgiunti, la distribuzione si può modellare come segue:
\[
P(X=k) = p^k\cdot (1-p) + (1-p)^k \cdot p    
\]

Il valore atteso:
\begin{align*}
    &E[X] = \sum_{i=0}^{\infty}i\cdot p^i(1-p)+\sum_{i=0}^{\infty}i(1-p)^ip = \\
    &(1-p)\sum_{i=0}^{\infty}ip^{i+1-1}+\sum_{i=0}^{\infty}i(1-p)^{i-1+1} = \\
    &(1-p)p\sum_{i=0}^{\infty}\frac{d}{dp}p^i + p(1-p)\sum_{i=0}^{\infty}\frac{d}{dp}(-(1-p^i)) = \\
    &(1-p)p\frac{d}{dp}\left(\frac{1}{1-p}\right) + p(1-p)\cdot\frac{d}{dp}\left(-\sum_{i=0}^{\infty}(1-p)^i\right) = \\
    &\frac{(1-p)}{(1-p)^2}p+\frac{p(1-p)}{p} = \frac{p}{1-p} + \frac{1-p}{p}
\end{align*}

la Varianza:
\begin{align*}
    &Var(X) = E[X^2]-E[X]^2 = \\
    &\text{dove:} \\
    &E[X^2] = \sum_{i=0}^{\infty}i^2p^i(1-p)+ \sum_{i=0}^{\infty}i^2(1-p)^ip = \\
    &(1-p)p\frac{d}{dp}\left(\sum_{i=0}^{\infty}ip^i\right) + p(1-p)\frac{d}{dp}\left(-\sum_{i=0}^{\infty}i(1-p)^i\right) = \\
    &(1-p)p\frac{p}{(1-p)^2}+p(1-p)\frac{d}{dp}\left(-\frac{(1-p)}{p^2}\right) = \\
    &\frac{p^2}{1-p}+\frac{(1-p)(2-p)}{p^2} \\
    &\text{Quindi:} \\
    &Var(X) = \frac{p^2}{1-p}+\frac{(1-p)(2-p)}{p^2} - \left(\frac{2p^2+1-2p}{(1-p)p}\right)^2
\end{align*}

\newpage
\subsection*{Esercizio 6}
Utilizzando la disuguaglianza di Chebyshev:
\begin{align*}
    \begin{cases}
        &P(|X-\mu| < k\sigma) \ge 1-\frac{1}{k^2} \\
        &P(|\frac{S_n}{n}-p|< \delta) \ge 0.95 \\
    \end{cases}
\end{align*}

Mettendo a confronto si ha:
\begin{align*}
    \begin{cases}
        &X = \frac{S_n}{n} \\
        &\mu = p \\
        &k\sigma = \delta \implies k = \frac{\delta}{\sqrt[2]{\frac{p(1-p)}{n}}} \\
        &Var(X) = Var(\frac{S_n}{n}) = \frac{1}{n^2}Var(S_n) = \frac{np(1-p)}{n^2} \quad \text{Essendo X una binomiale} \\
        &Dev(X) = \sqrt[2]{\frac{p(1-p)}{n}} = \sigma \\
    \end{cases}
\end{align*}

Devo trovare il numero di lanci \(n\) affinché il tutto sia maggiore di 0.95, quindi:
\begin{align*}
    &1-\frac{1}{k^2} \ge 0.95 \\
    &0.05 \ge \frac{1}{k^2} \\
    &k^2 \ge \sqrt{\frac{1}{0.05}} = \sqrt{20} \\
    &\text{Sostituisco l'espressione di k trovata prima} \\
    &\frac{\delta}{\sqrt{\frac{p(1-p)}{n}}} \ge \sqrt{20} \\
    &n\ge \frac{20\cdot p(1-p)}{\delta^2}
\end{align*}
\end{document}